seed: 7.000000
n_iter: 30
scoring: roc_auc
-- SVM MODEL --
Number of experiments: 10
Best: 0.875000 using {'SVM__C': 50, 'SVM__gamma': 0.05, 'SVM__kernel': 'rbf', 'fs__n_features_to_select': 12}
Best Features: 0, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15
Features Importances:  True False  True False False  True  True  True  True  True False  True
  True  True  True  True
Best: 0.958333 using {'SVM__C': 400, 'SVM__gamma': 0.001, 'SVM__kernel': 'rbf', 'fs__n_features_to_select': 8}
Best Features: 2, 6, 7, 8, 9, 11, 13, 15
Features Importances: False False  True False False False  True  True  True  True False  True
 False  True False  True
Best: 0.908333 using {'SVM__C': 5, 'SVM__gamma': 0.05, 'SVM__kernel': 'rbf', 'fs__n_features_to_select': 12}
Best Features: 1, 2, 3, 5, 6, 7, 8, 9, 11, 13, 14, 15
Features Importances: False  True  True  True False  True  True  True  True  True False  True
 False  True  True  True
Best: 0.891667 using {'SVM__C': 50, 'SVM__gamma': 0.01, 'SVM__kernel': 'rbf', 'fs__n_features_to_select': 4}
Best Features: 2, 9, 13, 15
Features Importances: False False  True False False False False False False  True False False
 False  True False  True
Best: 0.933333 using {'SVM__C': 100, 'SVM__gamma': 0.01, 'SVM__kernel': 'rbf', 'fs__n_features_to_select': 12}
Best Features: 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 15
Features Importances: False  True  True  True False  True  True  True  True  True  True  True
 False  True False  True
Best: 0.916667 using {'SVM__C': 50, 'SVM__gamma': 0.05, 'SVM__kernel': 'rbf', 'fs__n_features_to_select': 12}
Best Features: 0, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15
Features Importances:  True False  True False False  True  True  True  True  True False  True
  True  True  True  True
Best: 1.000000 using {'SVM__C': 50, 'SVM__gamma': 0.1, 'SVM__kernel': 'rbf', 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.941667 using {'SVM__C': 400, 'SVM__gamma': 0.01, 'SVM__kernel': 'rbf', 'fs__n_features_to_select': 12}
Best Features: 0, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances:  True False False False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.925000 using {'SVM__C': 50, 'SVM__gamma': 0.01, 'SVM__kernel': 'rbf', 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.950000 using {'SVM__C': 200, 'SVM__gamma': 0.01, 'SVM__kernel': 'rbf', 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
AUC = 0.8466666666666667
-- KNN MODEL --
Number of experiments: 10
Best: 0.783333 using {'KNN__n_neighbors': 13, 'KNN__weights': 'distance', 'fs__n_features_to_select': 4}
Best Features: 6, 7, 8, 15
Features Importances: False False False False False False  True  True  True False False False
 False False False  True
Best: 0.875000 using {'KNN__n_neighbors': 11, 'KNN__weights': 'distance', 'fs__n_features_to_select': 12}
Best Features: 1, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15
Features Importances: False  True  True False False  True  True  True  True  True False  True
  True  True  True  True
Best: 0.850000 using {'KNN__n_neighbors': 13, 'KNN__weights': 'distance', 'fs__n_features_to_select': 12}
Best Features: 1, 2, 3, 5, 6, 7, 8, 9, 11, 13, 14, 15
Features Importances: False  True  True  True False  True  True  True  True  True False  True
 False  True  True  True
Best: 0.891667 using {'KNN__n_neighbors': 5, 'KNN__weights': 'distance', 'fs__n_features_to_select': 4}
Best Features: 2, 9, 13, 15
Features Importances: False False  True False False False False False False  True False False
 False  True False  True
Best: 0.875000 using {'KNN__n_neighbors': 9, 'KNN__weights': 'distance', 'fs__n_features_to_select': 12}
Best Features: 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 15
Features Importances: False  True  True  True False  True  True  True  True  True  True  True
 False  True False  True
Best: 0.808333 using {'KNN__n_neighbors': 5, 'KNN__weights': 'distance', 'fs__n_features_to_select': 4}
Best Features: 0, 8, 9, 13
Features Importances:  True False False False False False False False  True  True False False
 False  True False False
Best: 0.883333 using {'KNN__n_neighbors': 3, 'KNN__weights': 'distance', 'fs__n_features_to_select': 4}
Best Features: 2, 8, 9, 13
Features Importances: False False  True False False False False False  True  True False False
 False  True False False
Best: 0.900000 using {'KNN__n_neighbors': 3, 'KNN__weights': 'distance', 'fs__n_features_to_select': 4}
Best Features: 0, 9, 13, 15
Features Importances:  True False False False False False False False False  True False False
 False  True False  True
Best: 0.866667 using {'KNN__n_neighbors': 3, 'KNN__weights': 'distance', 'fs__n_features_to_select': 4}
Best Features: 2, 9, 11, 13
Features Importances: False False  True False False False False False False  True False  True
 False  True False False
Best: 0.875000 using {'KNN__n_neighbors': 5, 'KNN__weights': 'distance', 'fs__n_features_to_select': 4}
Best Features: 2, 8, 9, 13
Features Importances: False False  True False False False False False  True  True False False
 False  True False False
AUC = 0.7758333333333334
-- RF MODEL --
Number of experiments: 10
Best: 0.850000 using {'RF__max_depth': 2, 'RF__n_estimators': 200, 'fs__n_features_to_select': 12}
Best Features: 0, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15
Features Importances:  True False  True False False  True  True  True  True  True False  True
  True  True  True  True
Best: 0.908333 using {'RF__max_depth': 3, 'RF__n_estimators': 200, 'fs__n_features_to_select': 12}
Best Features: 1, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15
Features Importances: False  True  True False False  True  True  True  True  True False  True
  True  True  True  True
Best: 0.891667 using {'RF__max_depth': 4, 'RF__n_estimators': 60, 'fs__n_features_to_select': 12}
Best Features: 1, 2, 3, 5, 6, 7, 8, 9, 11, 13, 14, 15
Features Importances: False  True  True  True False  True  True  True  True  True False  True
 False  True  True  True
Best: 0.916667 using {'RF__max_depth': 3, 'RF__n_estimators': 200, 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.891667 using {'RF__max_depth': 3, 'RF__n_estimators': 400, 'fs__n_features_to_select': 12}
Best Features: 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 15
Features Importances: False  True  True  True False  True  True  True  True  True  True  True
 False  True False  True
Best: 0.875000 using {'RF__max_depth': 10, 'RF__n_estimators': 400, 'fs__n_features_to_select': 12}
Best Features: 0, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15
Features Importances:  True False  True False False  True  True  True  True  True False  True
  True  True  True  True
Best: 0.975000 using {'RF__max_depth': 4, 'RF__n_estimators': 400, 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.916667 using {'RF__max_depth': 4, 'RF__n_estimators': 100, 'fs__n_features_to_select': 12}
Best Features: 0, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances:  True False False False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.891667 using {'RF__max_depth': 10, 'RF__n_estimators': 400, 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.908333 using {'RF__max_depth': 5, 'RF__n_estimators': 60, 'fs__n_features_to_select': 4}
Best Features: 2, 8, 9, 13
Features Importances: False False  True False False False False False  True  True False False
 False  True False False
AUC = 0.8533333333333334
-- ADAB MODEL --
Number of experiments: 10
Best: 0.866667 using {'ADAB__base_estimator__max_depth': 2, 'ADAB__n_estimators': 400, 'fs__n_features_to_select': 12}
Best Features: 0, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15
Features Importances:  True False  True False False  True  True  True  True  True False  True
  True  True  True  True
Best: 0.908333 using {'ADAB__base_estimator__max_depth': 3, 'ADAB__n_estimators': 10, 'fs__n_features_to_select': 12}
Best Features: 1, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15
Features Importances: False  True  True False False  True  True  True  True  True False  True
  True  True  True  True
Best: 0.866667 using {'ADAB__base_estimator__max_depth': 2, 'ADAB__n_estimators': 60, 'fs__n_features_to_select': 12}
Best Features: 1, 2, 3, 5, 6, 7, 8, 9, 11, 13, 14, 15
Features Importances: False  True  True  True False  True  True  True  True  True False  True
 False  True  True  True
Best: 0.925000 using {'ADAB__base_estimator__max_depth': 3, 'ADAB__n_estimators': 10, 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.891667 using {'ADAB__base_estimator__max_depth': 2, 'ADAB__n_estimators': 400, 'fs__n_features_to_select': 12}
Best Features: 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 15
Features Importances: False  True  True  True False  True  True  True  True  True  True  True
 False  True False  True
Best: 0.891667 using {'ADAB__base_estimator__max_depth': 2, 'ADAB__n_estimators': 400, 'fs__n_features_to_select': 12}
Best Features: 0, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15
Features Importances:  True False  True False False  True  True  True  True  True False  True
  True  True  True  True
Best: 0.950000 using {'ADAB__base_estimator__max_depth': 2, 'ADAB__n_estimators': 200, 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.941667 using {'ADAB__base_estimator__max_depth': 3, 'ADAB__n_estimators': 30, 'fs__n_features_to_select': 12}
Best Features: 0, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances:  True False False False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.841667 using {'ADAB__base_estimator__max_depth': 3, 'ADAB__n_estimators': 10, 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.891667 using {'ADAB__base_estimator__max_depth': 3, 'ADAB__n_estimators': 30, 'fs__n_features_to_select': 4}
Best Features: 2, 8, 9, 13
Features Importances: False False  True False False False False False  True  True False False
 False  True False False
AUC = 0.8383333333333334
-- LGB MODEL --
Number of experiments: 10
Best: 0.500000 using {'LGB__max_depth': 1, 'LGB__n_estimators': 10, 'fs__n_features_to_select': 4}
Best Features: 6, 7, 8, 15
Features Importances: False False False False False False  True  True  True False False False
 False False False  True
Best: 0.500000 using {'LGB__max_depth': 1, 'LGB__n_estimators': 10, 'fs__n_features_to_select': 4}
Best Features: 2, 9, 11, 13
Features Importances: False False  True False False False False False False  True False  True
 False  True False False
Best: 0.500000 using {'LGB__max_depth': 1, 'LGB__n_estimators': 10, 'fs__n_features_to_select': 4}
Best Features: 3, 9, 13, 15
Features Importances: False False False  True False False False False False  True False False
 False  True False  True
Best: 0.500000 using {'LGB__max_depth': 1, 'LGB__n_estimators': 10, 'fs__n_features_to_select': 4}
Best Features: 2, 9, 13, 15
Features Importances: False False  True False False False False False False  True False False
 False  True False  True
Best: 0.700000 using {'LGB__max_depth': 1, 'LGB__n_estimators': 10, 'fs__n_features_to_select': 12}
Best Features: 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 15
Features Importances: False  True  True  True False  True  True  True  True  True  True  True
 False  True False  True
Best: 0.750000 using {'LGB__max_depth': 1, 'LGB__n_estimators': 60, 'fs__n_features_to_select': 8}
Best Features: 0, 2, 6, 7, 8, 9, 13, 15
Features Importances:  True False  True False False False  True  True  True  True False False
 False  True False  True
Best: 0.775000 using {'LGB__max_depth': 1, 'LGB__n_estimators': 10, 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.816667 using {'LGB__max_depth': 1, 'LGB__n_estimators': 200, 'fs__n_features_to_select': 8}
Best Features: 0, 6, 7, 8, 9, 11, 13, 15
Features Importances:  True False False False False False  True  True  True  True False  True
 False  True False  True
Best: 0.750000 using {'LGB__max_depth': 1, 'LGB__n_estimators': 200, 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.695833 using {'LGB__max_depth': 1, 'LGB__n_estimators': 100, 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
AUC = 0.7341666666666666
-- XGB MODEL --
Number of experiments: 10
Best: 0.925000 using {'XGB__max_depth': 3, 'XGB__n_estimators': 30, 'fs__n_features_to_select': 12}
Best Features: 0, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15
Features Importances:  True False  True False False  True  True  True  True  True False  True
  True  True  True  True
Best: 1.000000 using {'XGB__max_depth': 1, 'XGB__n_estimators': 200, 'fs__n_features_to_select': 12}
Best Features: 1, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15
Features Importances: False  True  True False False  True  True  True  True  True False  True
  True  True  True  True
Best: 0.916667 using {'XGB__max_depth': 2, 'XGB__n_estimators': 60, 'fs__n_features_to_select': 12}
Best Features: 1, 2, 3, 5, 6, 7, 8, 9, 11, 13, 14, 15
Features Importances: False  True  True  True False  True  True  True  True  True False  True
 False  True  True  True
Best: 0.933333 using {'XGB__max_depth': 1, 'XGB__n_estimators': 100, 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.925000 using {'XGB__max_depth': 3, 'XGB__n_estimators': 60, 'fs__n_features_to_select': 12}
Best Features: 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 15
Features Importances: False  True  True  True False  True  True  True  True  True  True  True
 False  True False  True
Best: 0.937500 using {'XGB__max_depth': 2, 'XGB__n_estimators': 30, 'fs__n_features_to_select': 8}
Best Features: 0, 2, 6, 7, 8, 9, 13, 15
Features Importances:  True False  True False False False  True  True  True  True False False
 False  True False  True
Best: 0.916667 using {'XGB__max_depth': 2, 'XGB__n_estimators': 30, 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.958333 using {'XGB__max_depth': 2, 'XGB__n_estimators': 60, 'fs__n_features_to_select': 12}
Best Features: 0, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances:  True False False False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.925000 using {'XGB__max_depth': 2, 'XGB__n_estimators': 10, 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
Best: 0.925000 using {'XGB__max_depth': 1, 'XGB__n_estimators': 30, 'fs__n_features_to_select': 4}
Best Features: 2, 8, 9, 13
Features Importances: False False  True False False False False False  True  True False False
 False  True False False
AUC = 0.8833333333333333
-- DT MODEL --
Number of experiments: 10
Best: 0.841667 using {'DT__criterion': 'entropy', 'DT__max_depth': 2, 'DT__splitter': 'best', 'fs__n_features_to_select': 12}
Best Features: 0, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15
Features Importances:  True False  True False False  True  True  True  True  True False  True
  True  True  True  True
The binary tree structure has 7 nodes and has the following tree structure:

node=0 is a split node: go to node 1 if X[:, 6] <= 0.16433963924646378 else to node 4.
	node=1 is a split node: go to node 2 if X[:, 9] <= -0.5821265876293182 else to node 3.
		node=2 is a leaf node.
		node=3 is a leaf node.
	node=4 is a split node: go to node 5 if X[:, 10] <= -0.7471849322319031 else to node 6.
		node=5 is a leaf node.
		node=6 is a leaf node.
Best: 0.879167 using {'DT__criterion': 'gini', 'DT__max_depth': 2, 'DT__splitter': 'best', 'fs__n_features_to_select': 12}
Best Features: 1, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15
Features Importances: False  True  True False False  True  True  True  True  True False  True
  True  True  True  True
The binary tree structure has 5 nodes and has the following tree structure:

node=0 is a split node: go to node 1 if X[:, 9] <= -0.5105477571487427 else to node 2.
	node=1 is a leaf node.
	node=2 is a split node: go to node 3 if X[:, 10] <= -0.5812531411647797 else to node 4.
		node=3 is a leaf node.
		node=4 is a leaf node.
Best: 0.800000 using {'DT__criterion': 'gini', 'DT__max_depth': 3, 'DT__splitter': 'random', 'fs__n_features_to_select': 8}
Best Features: 2, 3, 6, 7, 8, 9, 13, 15
Features Importances: False False  True  True False False  True  True  True  True False False
 False  True False  True
The binary tree structure has 13 nodes and has the following tree structure:

node=0 is a split node: go to node 1 if X[:, 5] <= -0.27594691633514545 else to node 8.
	node=1 is a split node: go to node 2 if X[:, 6] <= -0.32115011423082085 else to node 5.
		node=2 is a split node: go to node 3 if X[:, 5] <= -0.6889607028249621 else to node 4.
			node=3 is a leaf node.
			node=4 is a leaf node.
		node=5 is a split node: go to node 6 if X[:, 1] <= -0.5989841025993439 else to node 7.
			node=6 is a leaf node.
			node=7 is a leaf node.
	node=8 is a split node: go to node 9 if X[:, 3] <= -0.5303993094820404 else to node 10.
		node=9 is a leaf node.
		node=10 is a split node: go to node 11 if X[:, 4] <= -0.2807928251176114 else to node 12.
			node=11 is a leaf node.
			node=12 is a leaf node.
Best: 0.804167 using {'DT__criterion': 'entropy', 'DT__max_depth': 2, 'DT__splitter': 'best', 'fs__n_features_to_select': 4}
Best Features: 2, 9, 13, 15
Features Importances: False False  True False False False False False False  True False False
 False  True False  True
The binary tree structure has 7 nodes and has the following tree structure:

node=0 is a split node: go to node 1 if X[:, 2] <= -0.571446031332016 else to node 4.
	node=1 is a split node: go to node 2 if X[:, 0] <= -0.3078455328941345 else to node 3.
		node=2 is a leaf node.
		node=3 is a leaf node.
	node=4 is a split node: go to node 5 if X[:, 1] <= 0.050196544267237186 else to node 6.
		node=5 is a leaf node.
		node=6 is a leaf node.
Best: 0.854167 using {'DT__criterion': 'gini', 'DT__max_depth': 3, 'DT__splitter': 'random', 'fs__n_features_to_select': 8}
Best Features: 2, 6, 7, 8, 9, 10, 11, 13
Features Importances: False False  True False False False  True  True  True  True  True  True
 False  True False False
The binary tree structure has 13 nodes and has the following tree structure:

node=0 is a split node: go to node 1 if X[:, 5] <= -0.7270916860924937 else to node 6.
	node=1 is a split node: go to node 2 if X[:, 7] <= -0.5565458728123049 else to node 5.
		node=2 is a split node: go to node 3 if X[:, 0] <= -0.991276153820738 else to node 4.
			node=3 is a leaf node.
			node=4 is a leaf node.
		node=5 is a leaf node.
	node=6 is a split node: go to node 7 if X[:, 2] <= 0.12326444554485438 else to node 10.
		node=7 is a split node: go to node 8 if X[:, 2] <= -0.4814386291901893 else to node 9.
			node=8 is a leaf node.
			node=9 is a leaf node.
		node=10 is a split node: go to node 11 if X[:, 7] <= 0.6148690265491493 else to node 12.
			node=11 is a leaf node.
			node=12 is a leaf node.
Best: 0.879167 using {'DT__criterion': 'entropy', 'DT__max_depth': 3, 'DT__splitter': 'random', 'fs__n_features_to_select': 8}
Best Features: 0, 2, 6, 7, 8, 9, 13, 15
Features Importances:  True False  True False False False  True  True  True  True False False
 False  True False  True
The binary tree structure has 13 nodes and has the following tree structure:

node=0 is a split node: go to node 1 if X[:, 5] <= -0.14826509494579176 else to node 8.
	node=1 is a split node: go to node 2 if X[:, 6] <= -0.35616291056332006 else to node 5.
		node=2 is a split node: go to node 3 if X[:, 1] <= -1.1339723629023561 else to node 4.
			node=3 is a leaf node.
			node=4 is a leaf node.
		node=5 is a split node: go to node 6 if X[:, 1] <= -0.5179557366363824 else to node 7.
			node=6 is a leaf node.
			node=7 is a leaf node.
	node=8 is a split node: go to node 9 if X[:, 3] <= -0.7082390819903049 else to node 10.
		node=9 is a leaf node.
		node=10 is a split node: go to node 11 if X[:, 3] <= -0.23718691674627135 else to node 12.
			node=11 is a leaf node.
			node=12 is a leaf node.
Best: 0.829167 using {'DT__criterion': 'entropy', 'DT__max_depth': 5, 'DT__splitter': 'random', 'fs__n_features_to_select': 8}
Best Features: 2, 6, 7, 8, 9, 11, 13, 15
Features Importances: False False  True False False False  True  True  True  True False  True
 False  True False  True
The binary tree structure has 21 nodes and has the following tree structure:

node=0 is a split node: go to node 1 if X[:, 2] <= 1.1655279368802618 else to node 20.
	node=1 is a split node: go to node 2 if X[:, 2] <= -0.5363931890573084 else to node 9.
		node=2 is a split node: go to node 3 if X[:, 6] <= -0.30564563943950795 else to node 4.
			node=3 is a leaf node.
			node=4 is a split node: go to node 5 if X[:, 7] <= -0.2994795278568988 else to node 6.
				node=5 is a leaf node.
				node=6 is a split node: go to node 7 if X[:, 3] <= -0.36739063438155617 else to node 8.
					node=7 is a leaf node.
					node=8 is a leaf node.
		node=9 is a split node: go to node 10 if X[:, 3] <= -0.47645885711615216 else to node 15.
			node=10 is a split node: go to node 11 if X[:, 4] <= 0.8441666455006628 else to node 14.
				node=11 is a split node: go to node 12 if X[:, 2] <= -0.26288661956587606 else to node 13.
					node=12 is a leaf node.
					node=13 is a leaf node.
				node=14 is a leaf node.
			node=15 is a split node: go to node 16 if X[:, 3] <= 1.3120235582258084 else to node 19.
				node=16 is a split node: go to node 17 if X[:, 1] <= 0.12504169547007926 else to node 18.
					node=17 is a leaf node.
					node=18 is a leaf node.
				node=19 is a leaf node.
	node=20 is a leaf node.
Best: 0.883333 using {'DT__criterion': 'entropy', 'DT__max_depth': 4, 'DT__splitter': 'random', 'fs__n_features_to_select': 4}
Best Features: 0, 9, 13, 15
Features Importances:  True False False False False False False False False  True False False
 False  True False  True
The binary tree structure has 23 nodes and has the following tree structure:

node=0 is a split node: go to node 1 if X[:, 0] <= 0.47015254673380436 else to node 14.
	node=1 is a split node: go to node 2 if X[:, 2] <= 0.10715285035764288 else to node 9.
		node=2 is a split node: go to node 3 if X[:, 2] <= -0.2973597987573491 else to node 6.
			node=3 is a split node: go to node 4 if X[:, 2] <= -0.7594955403111182 else to node 5.
				node=4 is a leaf node.
				node=5 is a leaf node.
			node=6 is a split node: go to node 7 if X[:, 2] <= -0.17051292847192603 else to node 8.
				node=7 is a leaf node.
				node=8 is a leaf node.
		node=9 is a split node: go to node 10 if X[:, 0] <= -0.6740390699934862 else to node 11.
			node=10 is a leaf node.
			node=11 is a split node: go to node 12 if X[:, 1] <= -0.31702863886830657 else to node 13.
				node=12 is a leaf node.
				node=13 is a leaf node.
	node=14 is a split node: go to node 15 if X[:, 3] <= -1.2756820292370221 else to node 16.
		node=15 is a leaf node.
		node=16 is a split node: go to node 17 if X[:, 2] <= 0.7990535468926583 else to node 20.
			node=17 is a split node: go to node 18 if X[:, 1] <= -0.1999576516014377 else to node 19.
				node=18 is a leaf node.
				node=19 is a leaf node.
			node=20 is a split node: go to node 21 if X[:, 3] <= -0.7884437530372334 else to node 22.
				node=21 is a leaf node.
				node=22 is a leaf node.
Best: 0.791667 using {'DT__criterion': 'gini', 'DT__max_depth': 2, 'DT__splitter': 'best', 'fs__n_features_to_select': 4}
Best Features: 2, 9, 11, 13
Features Importances: False False  True False False False False False False  True False  True
 False  True False False
The binary tree structure has 7 nodes and has the following tree structure:

node=0 is a split node: go to node 1 if X[:, 3] <= -0.584839940071106 else to node 4.
	node=1 is a split node: go to node 2 if X[:, 0] <= -0.36118099093437195 else to node 3.
		node=2 is a leaf node.
		node=3 is a leaf node.
	node=4 is a split node: go to node 5 if X[:, 1] <= 0.23070891946554184 else to node 6.
		node=5 is a leaf node.
		node=6 is a leaf node.
Best: 0.879167 using {'DT__criterion': 'gini', 'DT__max_depth': 4, 'DT__splitter': 'random', 'fs__n_features_to_select': 4}
Best Features: 2, 8, 9, 13
Features Importances: False False  True False False False False False  True  True False False
 False  True False False
The binary tree structure has 9 nodes and has the following tree structure:

node=0 is a split node: go to node 1 if X[:, 3] <= 2.875208594845038 else to node 8.
	node=1 is a split node: go to node 2 if X[:, 3] <= -0.6808171168042385 else to node 3.
		node=2 is a leaf node.
		node=3 is a split node: go to node 4 if X[:, 1] <= -0.8036831417908146 else to node 5.
			node=4 is a leaf node.
			node=5 is a split node: go to node 6 if X[:, 2] <= 0.18386455521973089 else to node 7.
				node=6 is a leaf node.
				node=7 is a leaf node.
	node=8 is a leaf node.
AUC = 0.7975000000000001
-- LOGISTIC REGRESSION MODEL --
Number of experiments: 10
Best: 0.850000 using {'LOGR__C': 10, 'LOGR__penalty': 'l2', 'fs__n_features_to_select': 12}
Best Features: 0, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15
Features Importances:  True False  True False False  True  True  True  True  True False  True
  True  True  True  True
Coefficient of the features in the decision function:  [[-1.53204529 -2.3092683  -0.35282762  1.79021381  3.78584967 -3.05362809
   2.22275178  2.01964846  0.35752311  2.09347503  0.28981559  2.21395816]]
Best: 0.933333 using {'LOGR__C': 3, 'LOGR__penalty': 'l2', 'fs__n_features_to_select': 8}
Best Features: 2, 6, 7, 8, 9, 11, 13, 15
Features Importances: False False  True False False False  True  True  True  True False  True
 False  True False  True
Coefficient of the features in the decision function:  [[-2.10206392  1.00041563  1.4665795  -1.65004641  1.60905211  0.76517736
   2.05888692  1.12696971]]
Best: 0.883333 using {'LOGR__C': 2, 'LOGR__penalty': 'l2', 'fs__n_features_to_select': 4}
Best Features: 3, 9, 13, 15
Features Importances: False False False  True False False False False False  True False False
 False  True False  True
Coefficient of the features in the decision function:  [[-1.67378419  2.07492131  1.87565391  0.39097956]]
Best: 0.866667 using {'LOGR__C': 2, 'LOGR__penalty': 'l2', 'fs__n_features_to_select': 4}
Best Features: 2, 9, 13, 15
Features Importances: False False  True False False False False False False  True False False
 False  True False  True
Coefficient of the features in the decision function:  [[-1.48873943  1.94879404  2.10499     0.20777936]]
Best: 0.866667 using {'LOGR__C': 0.001, 'LOGR__penalty': 'l2', 'fs__n_features_to_select': 8}
Best Features: 2, 6, 7, 8, 9, 10, 11, 13
Features Importances: False False  True False False False  True  True  True  True  True  True
 False  True False False
Coefficient of the features in the decision function:  [[ 0.00733972 -0.0049546   0.00880585 -0.00941898  0.01096016  0.00969414
   0.0075334   0.00963486]]
Best: 0.850000 using {'LOGR__C': 3, 'LOGR__penalty': 'l2', 'fs__n_features_to_select': 8}
Best Features: 0, 2, 6, 7, 8, 9, 13, 15
Features Importances:  True False  True False False False  True  True  True  True False False
 False  True False  True
Coefficient of the features in the decision function:  [[-0.90478786 -0.80834547  1.31216727  1.4864844  -1.76809064  1.96330383
   2.18319176  1.23025424]]
Best: 0.875000 using {'LOGR__C': 0.1, 'LOGR__penalty': 'l2', 'fs__n_features_to_select': 8}
Best Features: 2, 6, 7, 8, 9, 11, 13, 15
Features Importances: False False  True False False False  True  True  True  True False  True
 False  True False  True
Coefficient of the features in the decision function:  [[-0.05297547  0.01870289  0.29447726 -0.28976434  0.31816217  0.06400115
   0.26477419  0.02471841]]
Best: 0.916667 using {'LOGR__C': 5, 'LOGR__penalty': 'l2', 'fs__n_features_to_select': 4}
Best Features: 0, 9, 13, 15
Features Importances:  True False False False False False False False False  True False False
 False  True False  True
Coefficient of the features in the decision function:  [[-2.28297584  4.28109408  2.90845644  0.73947934]]
Best: 0.866667 using {'LOGR__C': 5, 'LOGR__penalty': 'l2', 'fs__n_features_to_select': 4}
Best Features: 2, 9, 11, 13
Features Importances: False False  True False False False False False False  True False  True
 False  True False False
Coefficient of the features in the decision function:  [[-3.17301806  2.67390559  1.0981146   2.29307434]]
Best: 0.900000 using {'LOGR__C': 3, 'LOGR__penalty': 'l2', 'fs__n_features_to_select': 12}
Best Features: 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
Features Importances: False False  True False False  True  True  True  True  True  True  True
  True  True  True  True
Coefficient of the features in the decision function:  [[-1.73371104 -0.37495654  0.69628165  1.85377349 -1.50304247  1.77887899
  -0.41515342  0.98780155  0.65769079  1.35647461  0.42857083  1.1791158 ]]
AUC = 0.8783333333333334

 
Warning
Figures now render in the Plots pane by default. To make them also appear inline in the Console, uncheck "Mute Inline Plotting" under the Plots pane options menu.
               SensLevel0          SensLevel1  ...  SpeCI_lo  SpeCI_hi
SVM   0.4583333333333333  0.7916666666666666  ...  0.543992  0.896008
KNN   0.5416666666666666               0.625  ...  0.752615  1.007385
ADAB  0.4583333333333333  0.7083333333333334  ...  0.543992  0.896008
RF    0.5833333333333334  0.7083333333333334  ...  0.543992  0.896008
LGB                 0.25                 0.5  ...   0.40796   0.79204
XGB                0.625               0.875  ...  0.752615  1.007385
DT    0.6458333333333333            0.796875  ...  0.592583  0.927417
LOGR               0.625  0.9166666666666666  ...  0.592583  0.927417

[8 rows x 12 columns]
Elapsed time:  907.4958984851837